{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Training and updating models\n",
    "\n",
    "Training and updating spaCy neural network models - focusing in NER.\n",
    "    \n",
    "\n",
    "#### Why updating the model?\n",
    "    \n",
    "- Better results on your specic domain\n",
    "- Learn classication schemes specically for your problem\n",
    "- Essential for text classication\n",
    "- Very useful for named entity recognition\n",
    "- Less critical for part-of-speech tagging and dependency parsing\n",
    "    \n",
    "#### How training works\n",
    "1. Initialize the model weights randomly with nlp.begin_training\n",
    "2. Predict a few examples with the current weights by calling nlp.update\n",
    "3. Compare prediction with true labels\n",
    "4. Calculate how to change weights to improve predictions\n",
    "5. Update weights slightly\n",
    "6. Go back to 2.\n",
    "    \n",
    "    \n",
    "<img src=\"https://d33wubrfki0l68.cloudfront.net/a634ac2555f216f30e47a08312745a85e552f4f1/b1d15/training-73950e71e6b59678754a87d6cf1481f9.svg\" width=\"800\" height=\"800\">   \n",
    "    \n",
    "- Training data: Examples and their annotations.\n",
    "- Text: The input text the model should predict a label for.\n",
    "- Label: The labelthe model should predict.\n",
    "- Gradient: How to change the weights.\n",
    "    \n",
    "    \n",
    "#### Example: Training the entity recognizer\n",
    "- The entity recognizer tags words and phrases in context\n",
    "- Each token can only be part of one entity\n",
    "- Examples need to come with context\n",
    "    \n",
    "` (\"iPhone X is coming\" , {'entities': [(0, 8, 'GADGET')]}) `\n",
    "- Texts with no entities are also important\n",
    "    \n",
    "` (\"I need a new phone! Any tips?\", {'entities': []})`\n",
    "- Goal:teach the model to generalize\n",
    "       \n",
    "#### The training data\n",
    "- Examples of what we want the modelto predict in context\n",
    "- Update an existing model: a few hundred to a few thousand examples\n",
    "- Train a new category: a few thousand to a million examples\n",
    "    - spaCy's English models: 2 million words\n",
    "- Usually created manually by human annotators\n",
    "- Can be semi-automated â€“ for example, using spaCy's Matcher !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating training data example:\n",
    "spaCy's rule-based Matcher is a great way to quickly create training data for named entity models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT=['How to preorder the iPhone X',\n",
    " 'iPhone X is coming',\n",
    " 'Should I pay $1,000 for the iPhone X?',\n",
    " 'The iPhone 8 reviews are here',\n",
    " 'Your iPhone goes up to 11 today',\n",
    " 'I need a new phone! Any tips?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp=English()\n",
    "\n",
    "# Initialize the Matcher and add the patterns\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{'LOWER': 'iphone'}, {'LOWER': 'x'}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{'LOWER': 'iphone'}, {'IS_DIGIT': True, 'OP': '?'}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add('GADGET', None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to preorder the iPhone X [(4, 6, 'GADGET'), (4, 5, 'GADGET')]\n",
      "iPhone X is coming [(0, 2, 'GADGET'), (0, 1, 'GADGET')]\n",
      "Should I pay $1,000 for the iPhone X? [(7, 9, 'GADGET'), (7, 8, 'GADGET')]\n",
      "The iPhone 8 reviews are here [(1, 2, 'GADGET'), (1, 3, 'GADGET')]\n",
      "Your iPhone goes up to 11 today [(1, 2, 'GADGET')]\n",
      "I need a new phone! Any tips? []\n"
     ]
    }
   ],
   "source": [
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXT):\n",
    "    # Find the matches in the doc\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Get a list of (start, end, label) tuples of matches in the text\n",
    "    entities = [(start, end, 'GADGET') for index, start, end in matches]\n",
    "    print(doc.text, entities) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 'GADGET')\n",
      "(1, 3, 'GADGET')\n"
     ]
    }
   ],
   "source": [
    "for x in [(1, 2, 'GADGET'), (1, 3, 'GADGET')]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXT):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    \n",
    "    ### filter overlapping spans\n",
    "    filtered = spacy.util.filter_spans(spans)\n",
    "    \n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, 'GADGET') for span in filtered]\n",
    "    \n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {'entities': entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "    \n",
    "print(*TRAINING_DATA, sep='\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> The training loop\n",
    "\n",
    "Spacy gives full control over the training loop.\n",
    "    \n",
    "\n",
    "#### The steps of a training loop\n",
    "- Series of steps that{s performed to train or update a model.\n",
    "    \n",
    "1. Loop for a number of times. (model can learn effectively)\n",
    "2. Shuffle the training data (preventing the model from getting stuck in a suboptimal solution)\n",
    "3. Divide the data into batches. (also call minibatching , this makes easier to make a more accurate estimate of the gradient)\n",
    "4. Update the model for each batch.\n",
    "5. Save the updated model.    \n",
    "        \n",
    "<img src=\"https://d33wubrfki0l68.cloudfront.net/a634ac2555f216f30e47a08312745a85e552f4f1/b1d15/training-73950e71e6b59678754a87d6cf1481f9.svg\" width=\"800\" height=\"800\">   \n",
    "\n",
    "#### Updating an existing model\n",
    "    \n",
    "- Improve the predictions on new data\n",
    "- Especially useful to improve existing categories, like PERSON\n",
    "- Also possible to add new categories\n",
    "- Be careful and make sure the model doesn't \"forget\" the old ones (make sure to use examples of the new categories and the old)\n",
    "    \n",
    "#### Setting up a new pipeline from scratch example\n",
    "prepare a spaCy pipeline to train the entity recognizer to recognize 'GADGET' entities in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x2a3e4e6d588>)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# Create a blank 'en' model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Create a new entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "# Add the label 'GADGET' to the entity recognizer\n",
    "ner.add_label('GADGET')\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 15.833333730697632}\n",
      "{'ner': 23.832850575447083}\n",
      "{'ner': 33.59307312965393}\n",
      "{'ner': 5.8727701008319855}\n",
      "{'ner': 14.006607383489609}\n",
      "{'ner': 20.45204469561577}\n",
      "{'ner': 2.446519672870636}\n",
      "{'ner': 6.871846782974899}\n",
      "{'ner': 10.04149281885475}\n",
      "{'ner': 1.2218325913418084}\n",
      "{'ner': 3.6921539160830434}\n",
      "{'ner': 6.993714232550701}\n",
      "{'ner': 3.369400496594608}\n",
      "{'ner': 5.634716486092657}\n",
      "{'ner': 9.70386698609218}\n",
      "{'ner': 3.141834852285683}\n",
      "{'ner': 4.4143831285400665}\n",
      "{'ner': 7.627638988451508}\n",
      "{'ner': 0.8304325730150595}\n",
      "{'ner': 2.970588672587837}\n",
      "{'ner': 4.8794374020963005}\n",
      "{'ner': 0.8755696392472601}\n",
      "{'ner': 0.9817464473417203}\n",
      "{'ner': 3.6814402281124785}\n",
      "{'ner': 1.5681217284000013}\n",
      "{'ner': 2.165615670730613}\n",
      "{'ner': 2.681548525042995}\n",
      "{'ner': 0.08017386267886195}\n",
      "{'ner': 0.08304749466278283}\n",
      "{'ner': 2.4762319764478598}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "    \n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "        \n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the model\n",
    "View how the model performs on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA=['Apple is slowing down the iPhone 8 and iPhone X - how to stop it',\n",
    " \"I finally understand what the iPhone X 'notch' is for\",\n",
    " 'Everything you need to know about the Samsung Galaxy S9',\n",
    " 'Looking to compare iPad models? Hereâ€™s how the 2018 lineup stacks up',\n",
    " 'The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple',\n",
    " 'what is the cheapest ipad, especially ipad pro???',\n",
    " 'Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is slowing down the iPhone 8 and iPhone X - how to stop it\n",
      "(iPhone 8, iPhone X) \n",
      "\n",
      "\n",
      "I finally understand what the iPhone X 'notch' is for\n",
      "(iPhone X,) \n",
      "\n",
      "\n",
      "Everything you need to know about the Samsung Galaxy S9\n",
      "() \n",
      "\n",
      "\n",
      "Looking to compare iPad models? Hereâ€™s how the 2018 lineup stacks up\n",
      "() \n",
      "\n",
      "\n",
      "The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple\n",
      "(iPhone 8, iPhone 8) \n",
      "\n",
      "\n",
      "what is the cheapest ipad, especially ipad pro???\n",
      "() \n",
      "\n",
      "\n",
      "Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics\n",
      "() \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each text in TEST_DATA\n",
    "for doc in nlp.pipe(TEST_DATA):\n",
    "    # Print the document text and entitites\n",
    "    print(doc.text)\n",
    "    print(doc.ents, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Best practices for training spaCy models\n",
    "\n",
    "\n",
    "#### Problem 1: Models can \"forget\" things\n",
    "- Existing model can overt on new data\n",
    "- e.g.: if you only update it with WEBSITE , it can \"unlearn\" what a PERSON is\n",
    "- Also known as \"catastrophic forgetting\" problem\n",
    "    \n",
    "#### Solution 1: Mix in previously correct predictions\n",
    "- For example, if you're training WEBSITE , also include examples of PERSON\n",
    "- Run existing spaCy model over data and extract all other relevant entities\n",
    "\n",
    "BAD:\n",
    "    \n",
    "```\n",
    "    TRAINING_DATA = [('Reddit is a website', {'entities': [(0, 6, 'WEBSITE')]})] \n",
    "    \n",
    "```\n",
    "\n",
    "GOOD:\n",
    "    \n",
    "```\n",
    "    TRAINING_DATA = [('Reddit is a website', {'entities': [(0, 6, 'WEBSITE')]}),\n",
    "    ('Obama is a person', {'entities': [(0, 5, 'PERSON')]})]\n",
    "    \n",
    "```\n",
    "    \n",
    "#### Problem 2: Models can'tlearn everything\n",
    "    \n",
    "- spaCy's models make predictions based on local context\n",
    "- Model can struggle to learn if decision is difcult to make based on context\n",
    "- Label scheme needs to be consistent and not too specic\n",
    "- For example: CLOTHING is better than ADULT_CLOTHING and CHILDRENS_CLOTHING  \n",
    "    \n",
    "    \n",
    "#### Solution 2: Plan your label scheme carefully\n",
    "- Pick categories that are reected in local context\n",
    "- More generic is better than too specic\n",
    "- Use rules to go from generic labels to specic categories\n",
    "    \n",
    "BAD:\n",
    "    \n",
    "```   \n",
    "    LABELS = ['ADULT_SHOES','CHILDRENS_SHOES','BANDS_I_LIKE']\n",
    "```\n",
    "    \n",
    "GOOD:\n",
    "\n",
    "```\n",
    "    LABELS = ['CLOTHING','BAND']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD LABELING\n",
      "('i went to amsterdem last year and the canals were beautiful', {'entities': [(10, 19, 'TOURIST_DESTINATION')]})\n",
      "('You should visit Paris once in your life, but the Eiffel Tower is kinda boring', {'entities': [(17, 22, 'TOURIST_DESTINATION')]})\n",
      "(\"There's also a Paris in Arkansas, lol\", {'entities': []})\n",
      "('Berlin is perfect for summer holiday: lots of parks, great nightlife, cheap beer!', {'entities': [(0, 6, 'TOURIST_DESTINATION')]})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = [\n",
    "  ('i went to amsterdem last year and the canals were beautiful', {'entities': [(10, 19, 'TOURIST_DESTINATION')]}),\n",
    "('You should visit Paris once in your life, but the Eiffel Tower is kinda boring', {'entities': [(17, 22, 'TOURIST_DESTINATION')]}),\n",
    "(\"There's also a Paris in Arkansas, lol\", {'entities': []}),\n",
    "('Berlin is perfect for summer holiday: lots of parks, great nightlife, cheap beer!', {'entities': [(0, 6, 'TOURIST_DESTINATION')]}),\n",
    "]\n",
    "print('BAD LABELING')\n",
    "print(*TRAINING_DATA, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOD LABELING\n",
      "('i went to amsterdem last year and the canals were beautiful', {'entities': [(10, 19, 'GPE')]})\n",
      "('You should visit Paris once in your life, but the Eiffel Tower is kinda boring', {'entities': [(17, 22, 'GPE')]})\n",
      "(\"There's also a Paris in Arkansas, lol\", {'entities': [(15, 20, 'GPE'), (24, 32, 'GPE')]})\n",
      "('Berlin is perfect for summer holiday: lots of parks, great nightlife, cheap beer!', {'entities': [(0, 6, 'GPE')]})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = [\n",
    "    (\"i went to amsterdem last year and the canals were beautiful\", {'entities': [(10, 19, 'GPE')]}),\n",
    "    (\"You should visit Paris once in your life, but the Eiffel Tower is kinda boring\", {'entities': [(17, 22, 'GPE')]}),\n",
    "    (\"There's also a Paris in Arkansas, lol\", {'entities': [(15, 20, 'GPE'), (24, 32, 'GPE')]}),\n",
    "    (\"Berlin is perfect for summer holiday: lots of parks, great nightlife, cheap beer!\", {'entities': [(0, 6, 'GPE')]})\n",
    "]\n",
    "print('GOOD LABELING')\n",
    "print(*TRAINING_DATA, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EXAMPLE OF TRAINING DATA\n",
    "TRAINING_DATA = [\n",
    "    (\"Reddit partners with Patreon to help creators build communities\", \n",
    "     {'entities': [(0, 6, 'WEBSITE'), (21, 28, 'WEBSITE')]}),\n",
    "  \n",
    "    (\"PewDiePie smashes YouTube record\", \n",
    "     {'entities': [(0,9,'PERSON'), (18, 25, 'WEBSITE')]}),\n",
    "  \n",
    "    (\"Reddit founder Alexis Ohanian gave away two Metallica tickets to fans\", \n",
    "     {'entities': [(0, 6, 'WEBSITE'), (15,29,'PERSON')]}),\n",
    "    # And so on...\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Wrapping up\n",
    "\n",
    "\n",
    "#### All learned on spaCy \n",
    "- Extract linguistic features: part-of-speech tags, dependencies, named entities\n",
    "- Work with pre-trained statistical models\n",
    "- Find words and phrases using Matcher and PhraseMatcher match rules\n",
    "- Best practices for working with data structures Doc , Token Span , Vocab , Lexeme\n",
    "- Find semantic similarities using word vectors\n",
    "- Write custom pipeline components with extension attributes\n",
    "- Scale up your spaCy pipelines and make them fast\n",
    "- Create training data for spaCy' statistical models\n",
    "- Train and update spaCy's neural network models with new data\n",
    "\n",
    "#### More things to do with spaCy\n",
    "- Training and updating other pipeline components (https://spacy.io/usage/training)\n",
    "    - Part-of-speech tagger\n",
    "    - Dependency parser\n",
    "    - Text classfier    \n",
    "    \n",
    "- Customizing the tokenizer (https://spacy.io/usage/linguistic-features#tokenization)\n",
    "    - Adding rules and exceptions to split text differently\\\n",
    "    \n",
    "- Adding or improving supportfor other languages (https://spacy.io/usage/adding-languages)\n",
    "    - 45+ languages currently\n",
    "    - Lots of room for improvement and more languages\n",
    "    - Allows training models for other languages\n",
    "    \n",
    "    \n",
    "SPACY DOCUMENTATION : https://spacy.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_text",
   "language": "python",
   "name": "ml_text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
